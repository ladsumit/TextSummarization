{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03914f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.43.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.14.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.24.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Downloading transformers-4.43.2-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.2-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.2/417.2 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=7b6cb853577e844cb8b6a5da1e4645894b92a0e5d3a4f6290cd1e3e4cf31d3eb\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: xxhash, safetensors, regex, pyarrow-hotfix, multidict, fsspec, frozenlist, async-timeout, absl-py, yarl, nltk, huggingface-hub, aiosignal, tokenizers, rouge_score, aiohttp, transformers, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.0\n",
      "    Uninstalling fsspec-2024.6.0:\n",
      "      Successfully uninstalled fsspec-2024.6.0\n",
      "Successfully installed absl-py-2.1.0 aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.20.0 frozenlist-1.4.1 fsspec-2024.5.0 huggingface-hub-0.24.2 multidict-6.0.5 nltk-3.8.1 pyarrow-hotfix-0.6 regex-2024.7.24 rouge_score-0.1.2 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.43.2 xxhash-3.4.1 yarl-1.9.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01142826bbd48b6bbc5594d2d6f0644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c503970a61a34cbd914f20b047f0f0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e23c9c86124161b6af157ae7df48c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8e1e98cf3e4a54bb7026c558728b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6f391d329649b280ad8b79bf5789f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5db97f833a458081e9415cf1c2f3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802762f717c04c0c8242b4dc24ea0894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9563fa843cf847a5ba473299c515d7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d098884362b463c9f51088bc28b9766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5c78d95d924c60a58ac1ebf2670f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3340548d77f64057bda7723963c2919d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b4d80de49744d4a911f9125993ba0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8112db80dbc4a00b19d5540893e8683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20055897fdac4b4e8d8d4c33be9b8391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2ae0af44554d3e8a601929ddf71391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7917/771616405.py:66: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge = load_metric(\"rouge\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83afa9233774752a6e0feab3ece805b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The repository for rouge contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/rouge.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N] y\n",
      "Few-shot learning results:\n",
      "\n",
      "Test Article 1:\n",
      "Generated Summary: \"Transplant tourists\" travel to poor countries to buy organs from the desperate. Pakistan, where trade in human organs is legal, is turning into a \"kidney bazaar\" O.J. Simpson will be held without bail after his arrest on robbery and assault charges.\n",
      "Reference Summary: London's Metropolitan Police say the man was arrested at Luton airport after landing on a flight from Istanbul .\n",
      "He's been charged with terror offenses allegedly committed since the start of November .\n",
      "ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.11904761904761904, recall=0.15151515151515152, fmeasure=0.13333333333333333), mid=Score(precision=0.11904761904761904, recall=0.15151515151515152, fmeasure=0.13333333333333333), high=Score(precision=0.11904761904761904, recall=0.15151515151515152, fmeasure=0.13333333333333333)), 'rouge2': AggregateScore(low=Score(precision=0.0, recall=0.0, fmeasure=0.0), mid=Score(precision=0.0, recall=0.0, fmeasure=0.0), high=Score(precision=0.0, recall=0.0, fmeasure=0.0)), 'rougeL': AggregateScore(low=Score(precision=0.07142857142857142, recall=0.09090909090909091, fmeasure=0.08), mid=Score(precision=0.07142857142857142, recall=0.09090909090909091, fmeasure=0.08), high=Score(precision=0.07142857142857142, recall=0.09090909090909091, fmeasure=0.08)), 'rougeLsum': AggregateScore(low=Score(precision=0.07142857142857142, recall=0.09090909090909091, fmeasure=0.08), mid=Score(precision=0.07142857142857142, recall=0.09090909090909091, fmeasure=0.08), high=Score(precision=0.07142857142857142, recall=0.09090909090909091, fmeasure=0.08))}\n",
      "\n",
      "Test Article 2:\n",
      "Generated Summary: \"Transplant tourists\" travel to poor countries to buy organs from the desperate. Pakistan, where trade in human organs is legal, is turning into a \"kidney bazaar\" O.J. Simpson is held without bail after his arrest on robbery and assault charges.\n",
      "Reference Summary: \"Furious 7\" pays tribute to star Paul Walker, who died during filming .\n",
      "Vin Diesel: \"This movie is more than a movie\"\n",
      "\"Furious 7\" opens Friday .\n",
      "ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.07317073170731707, recall=0.12, fmeasure=0.0909090909090909), mid=Score(precision=0.07317073170731707, recall=0.12, fmeasure=0.0909090909090909), high=Score(precision=0.07317073170731707, recall=0.12, fmeasure=0.0909090909090909)), 'rouge2': AggregateScore(low=Score(precision=0.0, recall=0.0, fmeasure=0.0), mid=Score(precision=0.0, recall=0.0, fmeasure=0.0), high=Score(precision=0.0, recall=0.0, fmeasure=0.0)), 'rougeL': AggregateScore(low=Score(precision=0.07317073170731707, recall=0.12, fmeasure=0.0909090909090909), mid=Score(precision=0.07317073170731707, recall=0.12, fmeasure=0.0909090909090909), high=Score(precision=0.07317073170731707, recall=0.12, fmeasure=0.0909090909090909)), 'rougeLsum': AggregateScore(low=Score(precision=0.07317073170731707, recall=0.12, fmeasure=0.0909090909090909), mid=Score(precision=0.07317073170731707, recall=0.12, fmeasure=0.0909090909090909), high=Score(precision=0.07317073170731707, recall=0.12, fmeasure=0.0909090909090909))}\n",
      "\n",
      "Test Article 3:\n",
      "Generated Summary: \"Transplant tourists\" travel to poor countries to buy organs from the desperate. Pakistan, where trade in human organs is legal, is turning into a \"kidney bazaar\" O.J. Simpson will be held without bail after his arrest on robbery and assault charges.\n",
      "Reference Summary: Museum: Anne Frank died earlier than previously believed .\n",
      "Researchers re-examined archives and testimonies of survivors .\n",
      "Anne and older sister Margot Frank are believed to have died in February 1945 .\n",
      "ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.07142857142857142, recall=0.1, fmeasure=0.08333333333333333), mid=Score(precision=0.07142857142857142, recall=0.1, fmeasure=0.08333333333333333), high=Score(precision=0.07142857142857142, recall=0.1, fmeasure=0.08333333333333333)), 'rouge2': AggregateScore(low=Score(precision=0.0, recall=0.0, fmeasure=0.0), mid=Score(precision=0.0, recall=0.0, fmeasure=0.0), high=Score(precision=0.0, recall=0.0, fmeasure=0.0)), 'rougeL': AggregateScore(low=Score(precision=0.047619047619047616, recall=0.06666666666666667, fmeasure=0.05555555555555555), mid=Score(precision=0.047619047619047616, recall=0.06666666666666667, fmeasure=0.05555555555555555), high=Score(precision=0.047619047619047616, recall=0.06666666666666667, fmeasure=0.05555555555555555)), 'rougeLsum': AggregateScore(low=Score(precision=0.07142857142857142, recall=0.1, fmeasure=0.08333333333333333), mid=Score(precision=0.07142857142857142, recall=0.1, fmeasure=0.08333333333333333), high=Score(precision=0.07142857142857142, recall=0.1, fmeasure=0.08333333333333333))}\n",
      "\n",
      "Test Article 4:\n",
      "Generated Summary: \"Transplant tourists\" travel to poor countries to buy organs from the desperate. Pakistan, where trade in human organs is legal, is turning into a \"kidney bazaar\" Former football star O.J. Simpson will be held without bail after his arrest.\n",
      "Reference Summary: LZ: Indiana law pushing back LGBT rights, and other states' anti-LGBT moves, bow to far right wing that GOP candidates need for 2016 .\n",
      "Cruz, Huckabee, Jindal, Carson, Walker are reviving culture wars, he says.  Equality for LGBT has not yet \"won\" in America .\n",
      "ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.05, recall=0.045454545454545456, fmeasure=0.04761904761904762), mid=Score(precision=0.05, recall=0.045454545454545456, fmeasure=0.04761904761904762), high=Score(precision=0.05, recall=0.045454545454545456, fmeasure=0.04761904761904762)), 'rouge2': AggregateScore(low=Score(precision=0.0, recall=0.0, fmeasure=0.0), mid=Score(precision=0.0, recall=0.0, fmeasure=0.0), high=Score(precision=0.0, recall=0.0, fmeasure=0.0)), 'rougeL': AggregateScore(low=Score(precision=0.05, recall=0.045454545454545456, fmeasure=0.04761904761904762), mid=Score(precision=0.05, recall=0.045454545454545456, fmeasure=0.04761904761904762), high=Score(precision=0.05, recall=0.045454545454545456, fmeasure=0.04761904761904762)), 'rougeLsum': AggregateScore(low=Score(precision=0.05, recall=0.045454545454545456, fmeasure=0.04761904761904762), mid=Score(precision=0.05, recall=0.045454545454545456, fmeasure=0.04761904761904762), high=Score(precision=0.05, recall=0.045454545454545456, fmeasure=0.04761904761904762))}\n",
      "\n",
      "Test Article 5:\n",
      "Generated Summary: \"Transplant tourists\" travel to poor countries to buy organs from the desperate. Pakistan, where trade in human organs is legal, is turning into a \"kidney bazaar\" Former football star O.J. Simpson will be held without bail after his arrest.\n",
      "Reference Summary: Singing the national anthem is a risky proposition .\n",
      "Whitney Houston nailed it; Roseanne Barr destroyed it .\n",
      "ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.075, recall=0.1875, fmeasure=0.10714285714285712), mid=Score(precision=0.075, recall=0.1875, fmeasure=0.10714285714285712), high=Score(precision=0.075, recall=0.1875, fmeasure=0.10714285714285712)), 'rouge2': AggregateScore(low=Score(precision=0.0, recall=0.0, fmeasure=0.0), mid=Score(precision=0.0, recall=0.0, fmeasure=0.0), high=Score(precision=0.0, recall=0.0, fmeasure=0.0)), 'rougeL': AggregateScore(low=Score(precision=0.075, recall=0.1875, fmeasure=0.10714285714285712), mid=Score(precision=0.075, recall=0.1875, fmeasure=0.10714285714285712), high=Score(precision=0.075, recall=0.1875, fmeasure=0.10714285714285712)), 'rougeLsum': AggregateScore(low=Score(precision=0.075, recall=0.1875, fmeasure=0.10714285714285712), mid=Score(precision=0.075, recall=0.1875, fmeasure=0.10714285714285712), high=Score(precision=0.075, recall=0.1875, fmeasure=0.10714285714285712))}\n",
      "Zero-shot learning results:\n",
      "\n",
      "Test Article 1:\n",
      "Generated Summary: Yahya Rashid, a UK national from northwest London, was detained at Luton airport on Tuesday. He's been charged with engaging in conduct in preparation of acts of terrorism.\n",
      "Reference Summary: London's Metropolitan Police say the man was arrested at Luton airport after landing on a flight from Istanbul .\n",
      "He's been charged with terror offenses allegedly committed since the start of November .\n",
      "ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.4827586206896552, recall=0.42424242424242425, fmeasure=0.45161290322580644), mid=Score(precision=0.4827586206896552, recall=0.42424242424242425, fmeasure=0.45161290322580644), high=Score(precision=0.4827586206896552, recall=0.42424242424242425, fmeasure=0.45161290322580644)), 'rouge2': AggregateScore(low=Score(precision=0.21428571428571427, recall=0.1875, fmeasure=0.19999999999999998), mid=Score(precision=0.21428571428571427, recall=0.1875, fmeasure=0.19999999999999998), high=Score(precision=0.21428571428571427, recall=0.1875, fmeasure=0.19999999999999998)), 'rougeL': AggregateScore(low=Score(precision=0.41379310344827586, recall=0.36363636363636365, fmeasure=0.3870967741935484), mid=Score(precision=0.41379310344827586, recall=0.36363636363636365, fmeasure=0.3870967741935484), high=Score(precision=0.41379310344827586, recall=0.36363636363636365, fmeasure=0.3870967741935484)), 'rougeLsum': AggregateScore(low=Score(precision=0.41379310344827586, recall=0.36363636363636365, fmeasure=0.3870967741935484), mid=Score(precision=0.41379310344827586, recall=0.36363636363636365, fmeasure=0.3870967741935484), high=Score(precision=0.41379310344827586, recall=0.36363636363636365, fmeasure=0.3870967741935484))}\n",
      "\n",
      "Test Article 2:\n",
      "Generated Summary: Paul Walker's death in November 2013 at the age of 40 after a car crash was especially eerie given his rise to fame in the \"Fast and Furious\" film franchise. \"He was a person of humility, integrity, and compassion,\" military veteran Kyle Upham said.\n",
      "Reference Summary: \"Furious 7\" pays tribute to star Paul Walker, who died during filming .\n",
      "Vin Diesel: \"This movie is more than a movie\"\n",
      "\"Furious 7\" opens Friday .\n",
      "ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.1111111111111111, recall=0.2, fmeasure=0.14285714285714285), mid=Score(precision=0.1111111111111111, recall=0.2, fmeasure=0.14285714285714285), high=Score(precision=0.1111111111111111, recall=0.2, fmeasure=0.14285714285714285)), 'rouge2': AggregateScore(low=Score(precision=0.022727272727272728, recall=0.041666666666666664, fmeasure=0.029411764705882356), mid=Score(precision=0.022727272727272728, recall=0.041666666666666664, fmeasure=0.029411764705882356), high=Score(precision=0.022727272727272728, recall=0.041666666666666664, fmeasure=0.029411764705882356)), 'rougeL': AggregateScore(low=Score(precision=0.08888888888888889, recall=0.16, fmeasure=0.1142857142857143), mid=Score(precision=0.08888888888888889, recall=0.16, fmeasure=0.1142857142857143), high=Score(precision=0.08888888888888889, recall=0.16, fmeasure=0.1142857142857143)), 'rougeLsum': AggregateScore(low=Score(precision=0.08888888888888889, recall=0.16, fmeasure=0.1142857142857143), mid=Score(precision=0.08888888888888889, recall=0.16, fmeasure=0.1142857142857143), high=Score(precision=0.08888888888888889, recall=0.16, fmeasure=0.1142857142857143))}\n",
      "\n",
      "Test Article 3:\n",
      "Generated Summary: Anne Frank died of typhus in a Nazi concentration camp at the age of 15. Just two weeks after her supposed death on March 31, 1945, the Bergen-Belsen concentration camp where she had been imprisoned was liberated. New research shows that Anne and her older sister, Margot Frank, died at least a month earlier than previously thought.\n",
      "Reference Summary: Museum: Anne Frank died earlier than previously believed .\n",
      "Researchers re-examined archives and testimonies of survivors .\n",
      "Anne and older sister Margot Frank are believed to have died in February 1945 .\n",
      "ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.27586206896551724, recall=0.5333333333333333, fmeasure=0.36363636363636365), mid=Score(precision=0.27586206896551724, recall=0.5333333333333333, fmeasure=0.36363636363636365), high=Score(precision=0.27586206896551724, recall=0.5333333333333333, fmeasure=0.36363636363636365)), 'rouge2': AggregateScore(low=Score(precision=0.14035087719298245, recall=0.27586206896551724, fmeasure=0.18604651162790697), mid=Score(precision=0.14035087719298245, recall=0.27586206896551724, fmeasure=0.18604651162790697), high=Score(precision=0.14035087719298245, recall=0.27586206896551724, fmeasure=0.18604651162790697)), 'rougeL': AggregateScore(low=Score(precision=0.1896551724137931, recall=0.36666666666666664, fmeasure=0.25), mid=Score(precision=0.1896551724137931, recall=0.36666666666666664, fmeasure=0.25), high=Score(precision=0.1896551724137931, recall=0.36666666666666664, fmeasure=0.25)), 'rougeLsum': AggregateScore(low=Score(precision=0.22413793103448276, recall=0.43333333333333335, fmeasure=0.29545454545454547), mid=Score(precision=0.22413793103448276, recall=0.43333333333333335, fmeasure=0.29545454545454547), high=Score(precision=0.22413793103448276, recall=0.43333333333333335, fmeasure=0.29545454545454547))}\n",
      "\n",
      "Test Article 4:\n",
      "Generated Summary: A year ago Bloomberg published a story with the following headline: Mike Pence, a Koch Favorite, Mulls 2016 Run for President. The story ticked off items on Pence's conservative things-to-do list while also noting his close ties to the deep-pocketed Koch brothers.\n",
      "Reference Summary: LZ: Indiana law pushing back LGBT rights, and other states' anti-LGBT moves, bow to far right wing that GOP candidates need for 2016 .\n",
      "Cruz, Huckabee, Jindal, Carson, Walker are reviving culture wars, he says.  Equality for LGBT has not yet \"won\" in America .\n",
      "ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.06521739130434782, recall=0.06818181818181818, fmeasure=0.06666666666666665), mid=Score(precision=0.06521739130434782, recall=0.06818181818181818, fmeasure=0.06666666666666665), high=Score(precision=0.06521739130434782, recall=0.06818181818181818, fmeasure=0.06666666666666665)), 'rouge2': AggregateScore(low=Score(precision=0.0, recall=0.0, fmeasure=0.0), mid=Score(precision=0.0, recall=0.0, fmeasure=0.0), high=Score(precision=0.0, recall=0.0, fmeasure=0.0)), 'rougeL': AggregateScore(low=Score(precision=0.043478260869565216, recall=0.045454545454545456, fmeasure=0.04444444444444444), mid=Score(precision=0.043478260869565216, recall=0.045454545454545456, fmeasure=0.04444444444444444), high=Score(precision=0.043478260869565216, recall=0.045454545454545456, fmeasure=0.04444444444444444)), 'rougeLsum': AggregateScore(low=Score(precision=0.043478260869565216, recall=0.045454545454545456, fmeasure=0.04444444444444444), mid=Score(precision=0.043478260869565216, recall=0.045454545454545456, fmeasure=0.04444444444444444), high=Score(precision=0.043478260869565216, recall=0.045454545454545456, fmeasure=0.04444444444444444))}\n",
      "\n",
      "Test Article 5:\n",
      "Generated Summary: Mötley Crüe's Vince Neil reminded us again this week of the dangers of tackling \"The Star-Spangled Banner\" Sure, he can shred it on \"Girls, Girls, Girls\" and \"Dr. Feelgood,\" but this is a different story.\n",
      "Reference Summary: Singing the national anthem is a risky proposition .\n",
      "Whitney Houston nailed it; Roseanne Barr destroyed it .\n",
      "ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.10256410256410256, recall=0.25, fmeasure=0.14545454545454548), mid=Score(precision=0.10256410256410256, recall=0.25, fmeasure=0.14545454545454548), high=Score(precision=0.10256410256410256, recall=0.25, fmeasure=0.14545454545454548)), 'rouge2': AggregateScore(low=Score(precision=0.02631578947368421, recall=0.06666666666666667, fmeasure=0.03773584905660377), mid=Score(precision=0.02631578947368421, recall=0.06666666666666667, fmeasure=0.03773584905660377), high=Score(precision=0.02631578947368421, recall=0.06666666666666667, fmeasure=0.03773584905660377)), 'rougeL': AggregateScore(low=Score(precision=0.07692307692307693, recall=0.1875, fmeasure=0.1090909090909091), mid=Score(precision=0.07692307692307693, recall=0.1875, fmeasure=0.1090909090909091), high=Score(precision=0.07692307692307693, recall=0.1875, fmeasure=0.1090909090909091)), 'rougeLsum': AggregateScore(low=Score(precision=0.10256410256410256, recall=0.25, fmeasure=0.14545454545454548), mid=Score(precision=0.10256410256410256, recall=0.25, fmeasure=0.14545454545454548), high=Score(precision=0.10256410256410256, recall=0.25, fmeasure=0.14545454545454548))}\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets rouge_score absl-py nltk\n",
    "\n",
    "# Import necessary libraries\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import random\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Sample 5 examples for few-shot learning\n",
    "few_shot_sample_indices = random.sample(range(100), 5)  # Using 100 to ensure enough data\n",
    "few_shot_examples = [\n",
    "    {\n",
    "        \"article\": dataset['train'][i]['article'],\n",
    "        \"summary\": dataset['train'][i]['highlights']\n",
    "    }\n",
    "    for i in few_shot_sample_indices\n",
    "]\n",
    "\n",
    "# Function to create few-shot prompt\n",
    "def create_few_shot_prompt(article, examples):\n",
    "    prompt = \"Here are some examples of article summaries:\\n\"\n",
    "    for ex in examples:\n",
    "        prompt += f\"Article: {ex['article'][:500]}...\\nSummary: {ex['summary']}\\n\\n\"  # Truncate long articles for prompt\n",
    "    prompt += f\"Now, summarize the following article:\\n{article[:500]}...\"  # Truncate long articles for prompt\n",
    "    return prompt\n",
    "\n",
    "# Function to create zero-shot prompt\n",
    "def create_zero_shot_prompt(article):\n",
    "    prompt = f\"Summarize the following article:\\n{article[:500]}...\"  # Truncate long articles for prompt\n",
    "    return prompt\n",
    "\n",
    "# Sample test articles\n",
    "test_sample_indices = range(10, 15)\n",
    "test_articles = [dataset['test'][i]['article'] for i in test_sample_indices]\n",
    "test_references = [dataset['test'][i]['highlights'] for i in test_sample_indices]\n",
    "\n",
    "# Generate few-shot prompts for test articles\n",
    "few_shot_prompts = [create_few_shot_prompt(article, few_shot_examples) for article in test_articles]\n",
    "# Generate zero-shot prompts for test articles\n",
    "zero_shot_prompts = [create_zero_shot_prompt(article) for article in test_articles]\n",
    "\n",
    "# Generate summaries using few-shot prompts\n",
    "few_shot_summaries = []\n",
    "for prompt in few_shot_prompts:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    few_shot_summaries.append(summary)\n",
    "\n",
    "# Generate summaries using zero-shot prompts\n",
    "zero_shot_summaries = []\n",
    "for prompt in zero_shot_prompts:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    zero_shot_summaries.append(summary)\n",
    "\n",
    "# Initialize ROUGE metric\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "# Evaluate the generated summaries using ROUGE\n",
    "few_shot_results = []\n",
    "for summary, reference in zip(few_shot_summaries, test_references):\n",
    "    result = rouge.compute(predictions=[summary], references=[reference])\n",
    "    few_shot_results.append(result)\n",
    "\n",
    "zero_shot_results = []\n",
    "for summary, reference in zip(zero_shot_summaries, test_references):\n",
    "    result = rouge.compute(predictions=[summary], references=[reference])\n",
    "    zero_shot_results.append(result)\n",
    "\n",
    "# Display results\n",
    "print(\"Few-shot learning results:\")\n",
    "for i, result in enumerate(few_shot_results):\n",
    "    print(f\"\\nTest Article {i+1}:\")\n",
    "    print(f\"Generated Summary: {few_shot_summaries[i]}\")\n",
    "    print(f\"Reference Summary: {test_references[i]}\")\n",
    "    print(f\"ROUGE Scores: {result}\")\n",
    "\n",
    "print(\"Zero-shot learning results:\")\n",
    "for i, result in enumerate(zero_shot_results):\n",
    "    print(f\"\\nTest Article {i+1}:\")\n",
    "    print(f\"Generated Summary: {zero_shot_summaries[i]}\")\n",
    "    print(f\"Reference Summary: {test_references[i]}\")\n",
    "    print(f\"ROUGE Scores: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b29f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
